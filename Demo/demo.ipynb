{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path('/home/danield/AnyoneAI/Curso/final_project/final_report/cnn+lstm/final-project-shot-type/models/utils_cnn_rnn.py').parent.parent))\n",
    "from models import utils_cnn_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danield/.local/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n",
      "/home/danield/.local/lib/python3.10/site-packages/gradio/interface.py:332: UserWarning: Currently, only the 'default' theme is supported.\n",
      "  warnings.warn(\"Currently, only the 'default' theme is supported.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def video_classifier(path):\n",
    "    sequence_model = keras.models.load_model(\"/home/danield/AnyoneAI/Curso/final_project/final_report/cnn+lstm/final-project-shot-type/Demo/84_percent_weight_and model/model.scale_84_percent.h5\")\n",
    "    sequence_model.load_weights('/home/danield/AnyoneAI/Curso/final_project/final_report/cnn+lstm/final-project-shot-type/Demo/84_percent_weight_and model/scale.weights_84_percent.h5')\n",
    "    result = utils_cnn_rnn.sequence_prediction(path, sequence_model)\n",
    "    return result, {\"mv1\": 0.40, \"mv2\": 0.50} # static prediction, movement prediction\n",
    "\n",
    "examples = [[\n",
    "    \"/home/danield/AnyoneAI/Curso/final_project/final_report/cnn+lstm/final-project-shot-type/Demo/tt0064755_0009.mp4\"\n",
    "]]\n",
    "title = \"\"\"\n",
    "Shot type classification for ads\n",
    "\"\"\"\n",
    "description=\"\"\"\n",
    "<p>\n",
    "<center>\n",
    "this is video classifier for adas which classify the shot type and shot movement\n",
    "<img src=\"https://anyirao.com/projects/eccv20shot/prototype.png\" height=250px width=500px>\n",
    "</center>\n",
    "</p>\n",
    "\"\"\"\n",
    "article = \"\"\"\n",
    "<p style='text-align: center'>\n",
    "<a href='https://medium.com/geekculture/discord-bot-using-dailogpt-and-huggingface-api-c71983422701' target='_blank'>Complete Tutorial</a>\n",
    "</p><p style='text-align: center'>\n",
    "<a href='https://dagshub.com/kingabzpro/DailoGPT-RickBot' target='_blank'>Project is Available at DAGsHub</a>\n",
    "</p></center><center><img src='https://visitor-badge.glitch.me/badge?page_id=kingabzpro/Rick_and_Morty_Bot' alt='visitor badge'></center></p>\n",
    "\"\"\"\n",
    "demo = gr.Interface(\n",
    "    fn=video_classifier, inputs=gr.Video(type=\"filepath\"), \n",
    "    outputs=[\"label\", \"label\"],\n",
    "    examples=examples,\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article,\n",
    "\ttheme=\"huggingface\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/danield/.local/lib/python3.10/site-packages/gradio/routes.py\", line 292, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"/home/danield/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1007, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"/home/danield/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 848, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/danield/.local/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/danield/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/danield/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/ipykernel_22101/3465491598.py\", line 4, in video_classifier\n",
      "    result = utils_cnn_rnn.sequence_prediction(path, sequence_model)\n",
      "  File \"/home/danield/AnyoneAI/Curso/final_project/final_report/cnn+lstm/final-project-shot-type/models/utils_cnn_rnn.py\", line 92, in sequence_prediction\n",
      "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
      "  File \"/home/danield/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/tmp/__autograph_generated_filel634ztkj.py\", line 15, in tf__predict_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"/home/danield/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/home/danield/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/danield/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n",
      "        outputs = model.predict_step(data)\n",
      "    File \"/home/danield/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1791, in predict_step\n",
      "        return self(x, training=False)\n",
      "    File \"/home/danield/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"/home/danield/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n",
      "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
      "\n",
      "    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 30, 2048), found shape=(None, 20, 2048)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "\n",
    "demo.launch(share=False, server_port=7860)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:50:25.374967: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 12:50:25.374983: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 12:50:28.516568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/danield/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-12-12 12:50:28.516583: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-12 12:50:28.516597: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (danieldpc): /proc/driver/nvidia/version does not exist\n",
      "2022-12-12 12:50:28.516717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path('/home/danield/AnyoneAI/Curso/final_project/final_report/final-project-shot-type-COMPLETE/models/utils_cnn_rnn.py').parent.parent))\n",
    "from models import utils_cnn_rnn\n",
    "sys.path.append(str(Path('/home/danield/AnyoneAI/Curso/final_project/final_report/final-project-shot-type-COMPLETE/models/utils_cnn3d.py').parent.parent))\n",
    "from models import utils_cnn3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danield/.local/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n",
      "/home/danield/.local/lib/python3.10/site-packages/gradio/interface.py:332: UserWarning: Currently, only the 'default' theme is supported.\n",
      "  warnings.warn(\"Currently, only the 'default' theme is supported.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "This function creates the models, loads the weights and make predictions of demo videos.\n",
    "'''\n",
    "\n",
    "def video_classifier(path):\n",
    "    \n",
    "    # scale shot type prediction\n",
    "    # Loading model \n",
    "    cnn_rnn_model = keras.models.load_model(\"/home/danield/AnyoneAI/Curso/final_project/final_report/final-project-shot-type-COMPLETE/Demo/scale_weight_and model/model.scale_84_percent.h5\")\n",
    "    # Loading weghts\n",
    "    cnn_rnn_model.load_weights('/home/danield/AnyoneAI/Curso/final_project/final_report/final-project-shot-type-COMPLETE/Demo/scale_weight_and model/scale.weights_84_percent.h5')\n",
    "    # getting results of prediction\n",
    "    result_scale = utils_cnn_rnn.sequence_prediction(path, cnn_rnn_model)\n",
    "\n",
    "    # movement shot type prediction\n",
    "    n_frames = 10\n",
    "    # Loading model\n",
    "    cnn3d_model = utils_cnn3d.create_cnn3d_model()\n",
    "    # Loading weghts    \n",
    "    cnn3d_model.load_weights('/home/danield/AnyoneAI/Curso/final_project/final_report/final-project-shot-type-COMPLETE/Demo/movement_model_and_weights/model.weights_conv_3d_f1_73_percent.h5')\n",
    "    # getting results of prediction\n",
    "    result_move = utils_cnn3d.sequence_prediction(path,n_frames, cnn3d_model)\n",
    "\n",
    "    return result_scale, result_move # static prediction, movement prediction\n",
    "\n",
    "\n",
    "#Gradio configuration\n",
    "\n",
    "examples = [[\n",
    "    \"/home/danield/AnyoneAI/Curso/final_project/final_report/final-project-shot-type-COMPLETE/Demo/tt0064755_0009.mp4\"\n",
    "]]\n",
    "title = \"\"\"\n",
    "Shot type classification for ads\n",
    "\"\"\"\n",
    "description=\"\"\"\n",
    "<p>\n",
    "<center>\n",
    "this is video classifier for adas which classify the shot type and shot movement\n",
    "<img src=\"https://anyirao.com/projects/eccv20shot/prototype.png\" height=250px width=500px>\n",
    "</center>\n",
    "</p>\n",
    "\"\"\"\n",
    "article = \"\"\"\n",
    "<p style='text-align: center'>\n",
    "<a href='https://medium.com/geekculture/discord-bot-using-dailogpt-and-huggingface-api-c71983422701' target='_blank'>Complete Tutorial</a>\n",
    "</p><p style='text-align: center'>\n",
    "<a href='https://dagshub.com/kingabzpro/DailoGPT-RickBot' target='_blank'>Project is Available at DAGsHub</a>\n",
    "</p></center><center><img src='https://visitor-badge.glitch.me/badge?page_id=kingabzpro/Rick_and_Morty_Bot' alt='visitor badge'></center></p>\n",
    "\"\"\"\n",
    "demo = gr.Interface(\n",
    "    fn=video_classifier, inputs=gr.Video(type=\"filepath\"), \n",
    "    outputs=[\"label\", \"label\"],\n",
    "    examples=examples,\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article,\n",
    "\ttheme=\"huggingface\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 615ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 525ms/step\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "\n",
    "demo.launch(share=False, server_port=7860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

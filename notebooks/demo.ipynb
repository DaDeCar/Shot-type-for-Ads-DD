{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from utils.util import load_df_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_DATA_FOLDER = 'trailer_v2'\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"../data/v1_split_trailer.json\"\n",
    "\n",
    "data_df = load_df_from_json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>movie</th>\n",
       "      <th>shot</th>\n",
       "      <th>scale_label</th>\n",
       "      <th>move_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>tt0444850</td>\n",
       "      <td>0014</td>\n",
       "      <td>CS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>tt0444850</td>\n",
       "      <td>0015</td>\n",
       "      <td>CS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>tt0444850</td>\n",
       "      <td>0016</td>\n",
       "      <td>ECS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>tt2005173</td>\n",
       "      <td>0002</td>\n",
       "      <td>MS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>tt2005173</td>\n",
       "      <td>0014</td>\n",
       "      <td>CS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33648</th>\n",
       "      <td>test</td>\n",
       "      <td>tt6644200</td>\n",
       "      <td>0011</td>\n",
       "      <td>FS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33649</th>\n",
       "      <td>test</td>\n",
       "      <td>tt6644200</td>\n",
       "      <td>0015</td>\n",
       "      <td>MS</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>test</td>\n",
       "      <td>tt6644200</td>\n",
       "      <td>0021</td>\n",
       "      <td>FS</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>test</td>\n",
       "      <td>tt6644200</td>\n",
       "      <td>0026</td>\n",
       "      <td>LS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>test</td>\n",
       "      <td>tt6644200</td>\n",
       "      <td>0042</td>\n",
       "      <td>ECS</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33653 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset      movie  shot scale_label move_label\n",
       "0       train  tt0444850  0014          CS     Static\n",
       "1       train  tt0444850  0015          CS     Static\n",
       "2       train  tt0444850  0016         ECS     Static\n",
       "3       train  tt2005173  0002          MS     Static\n",
       "4       train  tt2005173  0014          CS     Static\n",
       "...       ...        ...   ...         ...        ...\n",
       "33648    test  tt6644200  0011          FS     Static\n",
       "33649    test  tt6644200  0015          MS     Motion\n",
       "33650    test  tt6644200  0021          FS     Motion\n",
       "33651    test  tt6644200  0026          LS     Static\n",
       "33652    test  tt6644200  0042         ECS     Static\n",
       "\n",
       "[33653 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#json_path = '/workspaces/final-project-shot-type/data/CSV/dataset_df.csv'\n",
    "\n",
    "#data_df = pd. read_csv('/workspaces/final-project-shot-type/data/CSV/dataset_df.csv', dtype={\"shot\": str})\n",
    "\n",
    "\n",
    "# train_path = f'../data/{TRAIN_TEST_DATA_FOLDER}/train/'\n",
    "data_df['video_name'] = 'shot_' + data_df['movie'] + '_' + data_df['shot'] + '.mp4'\n",
    "train_df = data_df[data_df['dataset']=='train']\n",
    "train_df = train_df[['video_name', 'move_label','scale_label']]\n",
    "train_df = train_df.rename(columns ={'scale_label': 'tag'})\n",
    "\n",
    "\n",
    "#test_path = F'../data/{TRAIN_TEST_DATA_FOLDER}/test/'\n",
    "data_df['video_name'] = 'shot_' + data_df['movie'] + '_' + data_df['shot'] + '.mp4'\n",
    "test_df = data_df[data_df['dataset']=='test']\n",
    "test_df = test_df[['video_name', 'move_label','scale_label']]\n",
    "test_df = test_df.rename(columns ={'scale_label': 'tag'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20856, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 20856\n",
      "Total videos for testing: 8187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>move_label</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>shot_tt3922818_0092.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>shot_tt2390283_0055.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>shot_tt2327782_0046.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15479</th>\n",
       "      <td>shot_tt4161632_0045.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14439</th>\n",
       "      <td>shot_tt3954222_0070.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18789</th>\n",
       "      <td>shot_tt5084388_0074.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>shot_tt2186701_0051.mp4</td>\n",
       "      <td>Motion</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13324</th>\n",
       "      <td>shot_tt3747978_0045.mp4</td>\n",
       "      <td>Motion</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15657</th>\n",
       "      <td>shot_tt4193394_0048.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14897</th>\n",
       "      <td>shot_tt4047112_0007.mp4</td>\n",
       "      <td>Static</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    video_name move_label  tag\n",
       "14378  shot_tt3922818_0092.mp4     Static   FS\n",
       "4544   shot_tt2390283_0055.mp4     Static  ECS\n",
       "3639   shot_tt2327782_0046.mp4     Static   CS\n",
       "15479  shot_tt4161632_0045.mp4     Static   CS\n",
       "14439  shot_tt3954222_0070.mp4     Static   CS\n",
       "18789  shot_tt5084388_0074.mp4     Static   MS\n",
       "1976   shot_tt2186701_0051.mp4     Motion   LS\n",
       "13324  shot_tt3747978_0045.mp4     Motion   FS\n",
       "15657  shot_tt4193394_0048.mp4     Static   CS\n",
       "14897  shot_tt4047112_0007.mp4     Static  ECS"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df= train_df[0:12000]\n",
    "\n",
    "#test_df = test_df[0:3600]\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:07:48.196698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.204611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.205677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CS', 'ECS', 'FS', 'LS', 'MS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:07:48.207494: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 00:07:48.207898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.208758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.209689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.825228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.826045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.826808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-06 00:07:48.827537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_0 = np.load(\"../data/embeddings/12k_20_frames/train_data_embedding_0_12k.npy\")\n",
    "# train_data_1 = np.load(\"../data/embeddings/12k_20_frames/train_data_embedding_1_12k.npy\")\n",
    "\n",
    "# test_data_0 = np.load(\"../data/embeddings/12k_20_frames/test_data_embedding_0_12k.npy\")\n",
    "# test_data_1 = np.load(\"../data/embeddings/12k_20_frames/test_data_embedding_1_12k.npy\")\n",
    "\n",
    "# train_labels = np.load(\"../data/embeddings/12k_20_frames/train_labels_embedding_12k.npy\")\n",
    "# test_labels = np.load(\"../data/embeddings/12k_20_frames/test_labels_embedding_12k.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_0 = np.load(\"../data/all_20_frames/train_data_embedding_0_all_20frames.npy\")\n",
    "train_data_1 = np.load(\"../data/all_20_frames/train_data_embedding_1_all_20frames.npy\")\n",
    "\n",
    "test_data_0 = np.load(\"../data/all_20_frames/test_data_embedding_0_all_20frames.npy\")\n",
    "test_data_1 = np.load(\"../data/all_20_frames/test_data_embedding_1_all_20frames.npy\")\n",
    "\n",
    "train_labels = np.load(\"../data/all_20_frames/train_labels_embedding_all_20frames.npy\")\n",
    "test_labels = np.load(\"../data/all_20_frames/test_labels_embedding_all_20frames.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 00:08:09.720079: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467/468 [============================>.] - ETA: 0s - loss: 1.0906 - accuracy: 0.6450\n",
      "Epoch 1: val_loss improved from inf to 0.99348, saving model to /src/data/weights/model.01-0.9935.h5\n",
      "468/468 [==============================] - 24s 32ms/step - loss: 1.0904 - accuracy: 0.6450 - val_loss: 0.9935 - val_accuracy: 0.6028 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "465/468 [============================>.] - ETA: 0s - loss: 0.7955 - accuracy: 0.6673\n",
      "Epoch 2: val_loss did not improve from 0.99348\n",
      "468/468 [==============================] - 10s 21ms/step - loss: 0.7951 - accuracy: 0.6676 - val_loss: 0.9984 - val_accuracy: 0.6028 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "466/468 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.6676\n",
      "Epoch 3: val_loss did not improve from 0.99348\n",
      "468/468 [==============================] - 10s 21ms/step - loss: 0.7609 - accuracy: 0.6676 - val_loss: 1.0026 - val_accuracy: 0.6028 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "465/468 [============================>.] - ETA: 0s - loss: 0.7505 - accuracy: 0.6674\n",
      "Epoch 4: val_loss improved from 0.99348 to 0.98829, saving model to /src/data/weights/model.04-0.9883.h5\n",
      "468/468 [==============================] - 10s 21ms/step - loss: 0.7508 - accuracy: 0.6676 - val_loss: 0.9883 - val_accuracy: 0.6028 - lr: 5.0000e-04\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.6676\n",
      "Epoch 5: val_loss did not improve from 0.98829\n",
      "468/468 [==============================] - 10s 22ms/step - loss: 0.7436 - accuracy: 0.6676 - val_loss: 0.9895 - val_accuracy: 0.6028 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "466/468 [============================>.] - ETA: 0s - loss: 0.7415 - accuracy: 0.6677\n",
      "Epoch 6: val_loss improved from 0.98829 to 0.97897, saving model to /src/data/weights/model.06-0.9790.h5\n",
      "468/468 [==============================] - 10s 22ms/step - loss: 0.7414 - accuracy: 0.6676 - val_loss: 0.9790 - val_accuracy: 0.6028 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "465/468 [============================>.] - ETA: 0s - loss: 0.7373 - accuracy: 0.6679\n",
      "Epoch 7: val_loss did not improve from 0.97897\n",
      "468/468 [==============================] - 10s 21ms/step - loss: 0.7375 - accuracy: 0.6673 - val_loss: 0.9912 - val_accuracy: 0.6028 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "467/468 [============================>.] - ETA: 0s - loss: 0.7350 - accuracy: 0.6676\n",
      "Epoch 8: val_loss did not improve from 0.97897\n",
      "468/468 [==============================] - 10s 22ms/step - loss: 0.7350 - accuracy: 0.6676 - val_loss: 0.9978 - val_accuracy: 0.6028 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.7296 - accuracy: 0.6672\n",
      "Epoch 9: val_loss did not improve from 0.97897\n",
      "468/468 [==============================] - 10s 22ms/step - loss: 0.7296 - accuracy: 0.6672 - val_loss: 0.9878 - val_accuracy: 0.6028 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "466/468 [============================>.] - ETA: 0s - loss: 0.7288 - accuracy: 0.6683\n",
      "Epoch 10: val_loss did not improve from 0.97897\n",
      "468/468 [==============================] - 10s 22ms/step - loss: 0.7287 - accuracy: 0.6683 - val_loss: 0.9877 - val_accuracy: 0.6028 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(16)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"/src/data/weights/model.{epoch:02d}-{val_loss:.4f}.h5\"\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=2, min_lr=0.000001)\n",
    "    checkpoint_log = keras.callbacks.TensorBoard(\n",
    "        log_dir=\"/src/data/logs\"\n",
    "    )\n",
    "    checkpoint_weight = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data_0, train_data_1],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint_weight, reduce_lr, checkpoint_log],\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 03:49:39.187730: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 670679040 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 4s 7ms/step - loss: 0.6938 - accuracy: 0.7755\n",
      "Test accuracy: 77.55%\n"
     ]
    }
   ],
   "source": [
    "seq_model = keras.models.load_model(\"/src/data/weights/model.05-0.7091.h5\")\n",
    "_, accuracy = seq_model.evaluate([test_data_0, test_data_1], test_labels)\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.video import load_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path, sequence_model):\n",
    "    # class_vocab = label_processor.get_vocabulary()\n",
    "    class_vocab = ['CS', 'ECS', 'FS', 'LS', 'MS']\n",
    "    frames = load_video(os.path.join(\"test\", path), (IMG_SIZE, IMG_SIZE))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    result = {}\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        result[class_vocab[i]] = float(probabilities[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_model = keras.models.load_model(\"/src/data/weights/model.09-0.9950.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/src/data/trailer_v3/test/shot_tt2006051_0026.mp4\"\n",
    "result = sequence_prediction(path, sequence_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FS': 0.8643680214881897,\n",
       " 'LS': 0.09803581237792969,\n",
       " 'MS': 0.014811522327363491,\n",
       " 'CS': 0.011505961418151855,\n",
       " 'ECS': 0.011278731748461723}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.close_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/app/.local/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n",
      "/home/app/.local/lib/python3.8/site-packages/gradio/interface.py:330: UserWarning: Currently, only the 'default' theme is supported.\n",
      "  warnings.warn(\"Currently, only the 'default' theme is supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def video_classifier(path):\n",
    "    sequence_model = keras.models.load_model(\"/src/data/weights/model.09-0.9950.h5\")\n",
    "    result = sequence_prediction(path, sequence_model)\n",
    "    return result, {\"mv1\": 0.40, \"mv2\": 0.50} # static prediction, movement prediction\n",
    "\n",
    "examples = [[\n",
    "    \"shot_0084.mp4\"\n",
    "]]\n",
    "title = \"\"\"\n",
    "Shot type classification for ads\n",
    "\"\"\"\n",
    "description=\"\"\"\n",
    "<p>\n",
    "<center>\n",
    "this is video classifier for adas which classify the shot type and shot movement\n",
    "<img src=\"https://anyirao.com/projects/eccv20shot/prototype.png\" height=250px width=500px>\n",
    "</center>\n",
    "</p>\n",
    "\"\"\"\n",
    "article = \"\"\"\n",
    "<p style='text-align: center'>\n",
    "<a href='https://medium.com/geekculture/discord-bot-using-dailogpt-and-huggingface-api-c71983422701' target='_blank'>Complete Tutorial</a>\n",
    "</p><p style='text-align: center'>\n",
    "<a href='https://dagshub.com/kingabzpro/DailoGPT-RickBot' target='_blank'>Project is Available at DAGsHub</a>\n",
    "</p></center><center><img src='https://visitor-badge.glitch.me/badge?page_id=kingabzpro/Rick_and_Morty_Bot' alt='visitor badge'></center></p>\n",
    "\"\"\"\n",
    "demo = gr.Interface(\n",
    "    fn=video_classifier, inputs=gr.Video(type=\"filepath\"), \n",
    "    outputs=[\"label\", \"label\"],\n",
    "    examples=examples,\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article,\n",
    "\ttheme=\"huggingface\"\n",
    ")\n",
    "demo.launch(share=False, server_port=7860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

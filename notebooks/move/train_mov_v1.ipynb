{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "#from imutils import paths\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import imageio\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from ipywidgets import Video, Image\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 01:48:25.200473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:48:25.209502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-16 01:48:25.210409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "#Prevent tensorflow to allocate the entire GPU\n",
    "#https://www.tensorflow.org/api_docs/python/tf/config/experimental/set_memory_growth\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df= pd.read_csv('/home/app/src/data/CSV/dataset_train_v2+v3.csv', )\n",
    "# test_df= pd.read_csv('/home/app/src/data/CSV/dataset_test_v3.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('/home/app/src/CSV/dataset_train_v2+v3_with_rep_shuffle.csv')\n",
    "test_df= pd.read_csv('/home/app/src/CSV/dataset_test_v2+v3_with_rep_shuffle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.drop(columns =['tag','Unnamed: 0'])\n",
    "# train_df = train_df.rename(columns ={'move_label':'tag'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Pull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             video_name     tag\n",
       "0     /home/app/src/data/shot-type-dataset/trailer_v...    Push\n",
       "1     /home/app/src/data/shot-type-dataset/trailer_v...  Static\n",
       "2     /home/app/src/data/shot-type-dataset/trailer_v...  Motion\n",
       "3     /home/app/src/data/shot-type-dataset/trailer_v...    Pull\n",
       "4     /home/app/src/data/shot-type-dataset/trailer_v...  Static\n",
       "...                                                 ...     ...\n",
       "1185  /home/app/src/data/shot-type-dataset/trailer_v...  Motion\n",
       "1186  /home/app/src/data/shot-type-dataset/trailer_v...  Motion\n",
       "1187  /home/app/src/data/shot-type-dataset/trailer_v...  Static\n",
       "1188  /home/app/src/data/shot-type-dataset/trailer_v...  Static\n",
       "1189  /home/app/src/data/shot-type-dataset/trailer_v...  Motion\n",
       "\n",
       "[1190 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test_df.drop(columns =['tag','Unnamed: 0'])\n",
    "# test_df = test_df.rename(columns ={'move_label':'tag'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Pull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Pull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Pull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            video_name     tag\n",
       "0    /home/app/src/data/shot-type-dataset/trailer_v...    Push\n",
       "1    /home/app/src/data/shot-type-dataset/trailer_v...  Static\n",
       "2    /home/app/src/data/shot-type-dataset/trailer_v...  Motion\n",
       "3    /home/app/src/data/shot-type-dataset/trailer_v...    Pull\n",
       "4    /home/app/src/data/shot-type-dataset/trailer_v...    Pull\n",
       "..                                                 ...     ...\n",
       "315  /home/app/src/data/shot-type-dataset/trailer_v...  Motion\n",
       "316  /home/app/src/data/shot-type-dataset/trailer_v...    Push\n",
       "317  /home/app/src/data/shot-type-dataset/trailer_v...    Pull\n",
       "318  /home/app/src/data/shot-type-dataset/trailer_v...  Motion\n",
       "319  /home/app/src/data/shot-type-dataset/trailer_v...  Static\n",
       "\n",
       "[320 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking correct video tagging with original JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reading the JSON data using json.load()\n",
    "# json_path = '/home/app/src/data/shot-type-dataset/v1_split_trailer.json'\n",
    "# json_v2_path = '/home/app/src/data/shot-type-dataset/v2_full_trailer.json'\n",
    "\n",
    "# with open(json_path) as train_file:\n",
    "#     dict_v1= json.load(train_file)\n",
    "# with open(json_v2_path) as v2_file:\n",
    "#     dict_v2= json.load(v2_file)\n",
    "\n",
    "\n",
    "# def tag_ckecker (df, json_dict1, json_dict2, df_name_to_check):\n",
    "#     tag_chek_list = []\n",
    "\n",
    "#     for i in range(len(df.index)):\n",
    "#         movie = df['video_name'][i]\n",
    "#         df_tag = df['tag'][df['video_name'] == movie][i]\n",
    "#         find_char_st = movie.find('_', 55,60)\n",
    "#         find_char_end = movie.find('_', 65,70)\n",
    "#         movie_key = movie[find_char_st+1:find_char_end]\n",
    "#         trailer_key =  movie[find_char_end+1:find_char_end+5]\n",
    "#         try:\n",
    "#             dict_tag = json_dict1[df_name_to_check][movie_key][trailer_key]['movement']['label']\n",
    "#         except KeyError:\n",
    "#             try:\n",
    "#                 dict_tag = json_dict1['val'][movie_key][trailer_key]['movement']['label']\n",
    "#                 if dict_tag == df_tag:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     tag_chek_list.append(movie)\n",
    "#             except KeyError:\n",
    "#                 dict_tag = json_dict2[movie_key][trailer_key]['movement']['label']\n",
    "#                 if dict_tag == df_tag:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     tag_chek_list.append(movie)\n",
    "\n",
    "            \n",
    "\n",
    "#     if len(tag_chek_list) == 0:\n",
    "#         print(f'tag check {df_name_to_check} OK')\n",
    "#     else: print (tag_chek_list)\n",
    "\n",
    "\n",
    "# tag_ckecker(train_df, dict_v1, dict_v2, 'train')\n",
    "# tag_ckecker(test_df, dict_v1, dict_v2, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train value counts:\n",
      " Static    320\n",
      "Motion    320\n",
      "Push      303\n",
      "Pull      247\n",
      "Name: tag, dtype: int64 \n",
      "\n",
      "Test value counts:\n",
      " Push      80\n",
      "Static    80\n",
      "Motion    80\n",
      "Pull      80\n",
      "Name: tag, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Train value counts:' '\\n',train_df['tag'].value_counts(), '\\n')\n",
    "print(f'Test value counts:' '\\n',test_df['tag'].value_counts(), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "MAX_SEQ_LENGTH = 40\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading frames and working on frame's size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_2 (TFOpLamb  (None, 224, 224, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_2 (TFOpLam  (None, 224, 224, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 2048)              21802784  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()\n",
    "print(feature_extractor.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Motion', 'Pull', 'Push', 'Static']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    labels = df[\"tag\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "        print(f' {root_dir}_video {idx}/{len(video_paths)} done')\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "#train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "#print(f\"Frame features in train set: {train_data[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving TRAIN embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_save_embeddings= '/home/app/src/embeddings/emb_v2+v3_with_rep_shuffle_40F/'\n",
    "\n",
    "# # Train\n",
    "# train_data_embedding_0 = np.save(path_save_embeddings + 'train_data_embedding_0.npy', train_data[0])\n",
    "# train_data_embedding_1 = np.save(path_save_embeddings + 'train_data_embedding_1.npy', train_data[1])\n",
    "# train_labels_embedding = np.save(path_save_embeddings + 'train_labels_embedding.npy', train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing TEST videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "# print(f\"Frame masks in test set: {test_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving TEST embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test\n",
    "# test_data_embedding_0 = np.save(path_save_embeddings + 'test_data_embedding_0.npy', test_data[0])\n",
    "# test_data_embedding_1 = np.save(path_save_embeddings + 'test_data_embedding_1.npy', test_data[1])\n",
    "# test_labels_embedding = np.save(path_save_embeddings + 'test_labels_embedding.npy', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load_embeddings= '/home/app/src/embeddings/emb_v2+v3_with_rep_shuffle_40F/'\n",
    "\n",
    "#Train\n",
    "train_data_0 = np.load(path_load_embeddings + 'train_data_embedding_0.npy')\n",
    "train_data_1 = np.load(path_load_embeddings + 'train_data_embedding_1.npy')\n",
    "train_data=(train_data_0, train_data_1)\n",
    "train_labels = np.load(path_load_embeddings + 'train_labels_embedding.npy')\n",
    "\n",
    "#Test\n",
    "test_data_0 = np.load(path_load_embeddings + 'test_data_embedding_0.npy')\n",
    "test_data_1 = np.load(path_load_embeddings + 'test_data_embedding_1.npy')\n",
    "test_data=(test_data_0, test_data_1)\n",
    "test_labels = np.load(path_load_embeddings + 'test_labels_embedding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_load_labels= '/home/app/src/embeddings/aa/'\n",
    "# train_labels = np.load(path_load_labels + 'train_labels_embedding.npy')\n",
    "# test_labels = np.load(path_load_labels + 'test_labels_embedding.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence model (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.4638 - accuracy: 0.2440\n",
      "Epoch 1: val_loss improved from inf to 1.42508, saving model to /home/app/src/experiments/inceptionv3_GRU/exp_006/model.weights_exp_005.h5\n",
      "53/53 [==============================] - 14s 91ms/step - loss: 1.4645 - accuracy: 0.2437 - val_loss: 1.4251 - val_accuracy: 0.2829 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.4400 - accuracy: 0.2537\n",
      "Epoch 2: val_loss did not improve from 1.42508\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.4406 - accuracy: 0.2533 - val_loss: 1.4278 - val_accuracy: 0.2997 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.4328 - accuracy: 0.2837\n",
      "Epoch 3: val_loss improved from 1.42508 to 1.41476, saving model to /home/app/src/experiments/inceptionv3_GRU/exp_006/model.weights_exp_005.h5\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 1.4331 - accuracy: 0.2833 - val_loss: 1.4148 - val_accuracy: 0.3109 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.4185 - accuracy: 0.3100\n",
      "Epoch 4: val_loss did not improve from 1.41476\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.4177 - accuracy: 0.3085 - val_loss: 1.4181 - val_accuracy: 0.2997 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.3863 - accuracy: 0.3407\n",
      "Epoch 5: val_loss did not improve from 1.41476\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.3884 - accuracy: 0.3409 - val_loss: 1.4240 - val_accuracy: 0.3109 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.3784 - accuracy: 0.3341\n",
      "Epoch 6: val_loss improved from 1.41476 to 1.41019, saving model to /home/app/src/experiments/inceptionv3_GRU/exp_006/model.weights_exp_005.h5\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.3785 - accuracy: 0.3337 - val_loss: 1.4102 - val_accuracy: 0.3221 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.3612 - accuracy: 0.3385\n",
      "Epoch 7: val_loss improved from 1.41019 to 1.40804, saving model to /home/app/src/experiments/inceptionv3_GRU/exp_006/model.weights_exp_005.h5\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.3612 - accuracy: 0.3385 - val_loss: 1.4080 - val_accuracy: 0.3221 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.3375 - accuracy: 0.3652\n",
      "Epoch 8: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.3359 - accuracy: 0.3649 - val_loss: 1.4584 - val_accuracy: 0.3473 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.3116 - accuracy: 0.3954\n",
      "Epoch 9: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.3122 - accuracy: 0.3950 - val_loss: 1.4574 - val_accuracy: 0.3249 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2891 - accuracy: 0.4038\n",
      "Epoch 10: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2894 - accuracy: 0.4034 - val_loss: 1.4389 - val_accuracy: 0.3221 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2485 - accuracy: 0.4135\n",
      "Epoch 11: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2499 - accuracy: 0.4130 - val_loss: 1.4229 - val_accuracy: 0.3137 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.2467 - accuracy: 0.4547\n",
      "Epoch 12: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.2495 - accuracy: 0.4526 - val_loss: 1.4342 - val_accuracy: 0.3221 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.2146 - accuracy: 0.4724\n",
      "Epoch 13: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.2140 - accuracy: 0.4730 - val_loss: 1.4474 - val_accuracy: 0.3221 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1930 - accuracy: 0.4748\n",
      "Epoch 14: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1929 - accuracy: 0.4754 - val_loss: 1.4460 - val_accuracy: 0.3305 - lr: 2.5000e-05\n",
      "Epoch 15/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1980 - accuracy: 0.4645\n",
      "Epoch 15: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1978 - accuracy: 0.4646 - val_loss: 1.4560 - val_accuracy: 0.3249 - lr: 2.5000e-05\n",
      "Epoch 16/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1791 - accuracy: 0.4820\n",
      "Epoch 16: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1798 - accuracy: 0.4814 - val_loss: 1.4556 - val_accuracy: 0.3249 - lr: 2.5000e-05\n",
      "Epoch 17/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1754 - accuracy: 0.4951\n",
      "Epoch 17: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1741 - accuracy: 0.4982 - val_loss: 1.4483 - val_accuracy: 0.3389 - lr: 1.2500e-05\n",
      "Epoch 18/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1623 - accuracy: 0.5361\n",
      "Epoch 18: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1624 - accuracy: 0.5354 - val_loss: 1.4525 - val_accuracy: 0.3333 - lr: 1.2500e-05\n",
      "Epoch 19/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1623 - accuracy: 0.4808\n",
      "Epoch 19: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1623 - accuracy: 0.4814 - val_loss: 1.4508 - val_accuracy: 0.3389 - lr: 1.2500e-05\n",
      "Epoch 20/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1679 - accuracy: 0.5024\n",
      "Epoch 20: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 1.1673 - accuracy: 0.5030 - val_loss: 1.4533 - val_accuracy: 0.3445 - lr: 6.2500e-06\n",
      "Epoch 21/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1477 - accuracy: 0.5108\n",
      "Epoch 21: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1481 - accuracy: 0.5102 - val_loss: 1.4531 - val_accuracy: 0.3501 - lr: 6.2500e-06\n",
      "Epoch 22/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1473 - accuracy: 0.5312\n",
      "Epoch 22: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1472 - accuracy: 0.5318 - val_loss: 1.4519 - val_accuracy: 0.3501 - lr: 6.2500e-06\n",
      "Epoch 23/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1403 - accuracy: 0.5240\n",
      "Epoch 23: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1414 - accuracy: 0.5234 - val_loss: 1.4542 - val_accuracy: 0.3501 - lr: 3.1250e-06\n",
      "Epoch 24/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1395 - accuracy: 0.5168\n",
      "Epoch 24: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1401 - accuracy: 0.5162 - val_loss: 1.4581 - val_accuracy: 0.3445 - lr: 3.1250e-06\n",
      "Epoch 25/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1483 - accuracy: 0.5072\n",
      "Epoch 25: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1483 - accuracy: 0.5078 - val_loss: 1.4559 - val_accuracy: 0.3585 - lr: 3.1250e-06\n",
      "Epoch 26/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1438 - accuracy: 0.5098\n",
      "Epoch 26: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1417 - accuracy: 0.5138 - val_loss: 1.4549 - val_accuracy: 0.3557 - lr: 1.5625e-06\n",
      "Epoch 27/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1450 - accuracy: 0.5252\n",
      "Epoch 27: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1457 - accuracy: 0.5246 - val_loss: 1.4582 - val_accuracy: 0.3445 - lr: 1.5625e-06\n",
      "Epoch 28/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1411 - accuracy: 0.5216\n",
      "Epoch 28: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1407 - accuracy: 0.5222 - val_loss: 1.4590 - val_accuracy: 0.3501 - lr: 1.5625e-06\n",
      "Epoch 29/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1434 - accuracy: 0.5144\n",
      "Epoch 29: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1437 - accuracy: 0.5138 - val_loss: 1.4586 - val_accuracy: 0.3501 - lr: 1.0000e-06\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1399 - accuracy: 0.5222\n",
      "Epoch 30: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1399 - accuracy: 0.5222 - val_loss: 1.4581 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 31/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1480 - accuracy: 0.5180\n",
      "Epoch 31: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1473 - accuracy: 0.5186 - val_loss: 1.4576 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 32/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1470 - accuracy: 0.5349\n",
      "Epoch 32: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1469 - accuracy: 0.5342 - val_loss: 1.4577 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1392 - accuracy: 0.5306\n",
      "Epoch 33: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1392 - accuracy: 0.5306 - val_loss: 1.4573 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1409 - accuracy: 0.5210\n",
      "Epoch 34: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1409 - accuracy: 0.5210 - val_loss: 1.4556 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 35/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1406 - accuracy: 0.4976\n",
      "Epoch 35: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1405 - accuracy: 0.4970 - val_loss: 1.4567 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1398 - accuracy: 0.5084\n",
      "Epoch 36: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1394 - accuracy: 0.5090 - val_loss: 1.4576 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1472 - accuracy: 0.5012\n",
      "Epoch 37: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1475 - accuracy: 0.5006 - val_loss: 1.4557 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1339 - accuracy: 0.5098\n",
      "Epoch 38: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1351 - accuracy: 0.5078 - val_loss: 1.4546 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1443 - accuracy: 0.5135\n",
      "Epoch 39: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1435 - accuracy: 0.5126 - val_loss: 1.4555 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1360 - accuracy: 0.5196\n",
      "Epoch 40: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1339 - accuracy: 0.5186 - val_loss: 1.4554 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1365 - accuracy: 0.5208\n",
      "Epoch 41: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1344 - accuracy: 0.5198 - val_loss: 1.4557 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1448 - accuracy: 0.5018\n",
      "Epoch 42: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1448 - accuracy: 0.5018 - val_loss: 1.4576 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1367 - accuracy: 0.5144\n",
      "Epoch 43: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1369 - accuracy: 0.5138 - val_loss: 1.4573 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1420 - accuracy: 0.5325\n",
      "Epoch 44: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1425 - accuracy: 0.5318 - val_loss: 1.4584 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1415 - accuracy: 0.5084\n",
      "Epoch 45: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1416 - accuracy: 0.5090 - val_loss: 1.4577 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1348 - accuracy: 0.5186\n",
      "Epoch 46: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1348 - accuracy: 0.5186 - val_loss: 1.4588 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1340 - accuracy: 0.5252\n",
      "Epoch 47: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1345 - accuracy: 0.5246 - val_loss: 1.4593 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1430 - accuracy: 0.5144\n",
      "Epoch 48: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1431 - accuracy: 0.5150 - val_loss: 1.4587 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1319 - accuracy: 0.5228\n",
      "Epoch 49: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1317 - accuracy: 0.5222 - val_loss: 1.4589 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1322 - accuracy: 0.5144\n",
      "Epoch 50: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1329 - accuracy: 0.5138 - val_loss: 1.4594 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1289 - accuracy: 0.5312\n",
      "Epoch 51: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1295 - accuracy: 0.5306 - val_loss: 1.4579 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1354 - accuracy: 0.5264\n",
      "Epoch 52: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1363 - accuracy: 0.5258 - val_loss: 1.4581 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1387 - accuracy: 0.5048\n",
      "Epoch 53: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1393 - accuracy: 0.5042 - val_loss: 1.4576 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1459 - accuracy: 0.5120\n",
      "Epoch 54: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.1458 - accuracy: 0.5126 - val_loss: 1.4581 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1211 - accuracy: 0.5228\n",
      "Epoch 55: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 1.1214 - accuracy: 0.5222 - val_loss: 1.4586 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1407 - accuracy: 0.5180\n",
      "Epoch 56: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 2s 47ms/step - loss: 1.1403 - accuracy: 0.5186 - val_loss: 1.4590 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1383 - accuracy: 0.5222\n",
      "Epoch 57: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 2s 43ms/step - loss: 1.1383 - accuracy: 0.5222 - val_loss: 1.4587 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1247 - accuracy: 0.5186\n",
      "Epoch 58: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 3s 49ms/step - loss: 1.1247 - accuracy: 0.5186 - val_loss: 1.4590 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1294 - accuracy: 0.5216\n",
      "Epoch 59: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 3s 48ms/step - loss: 1.1292 - accuracy: 0.5210 - val_loss: 1.4592 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1379 - accuracy: 0.5397\n",
      "Epoch 60: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 1.1376 - accuracy: 0.5402 - val_loss: 1.4592 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1292 - accuracy: 0.5342\n",
      "Epoch 61: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 1.1292 - accuracy: 0.5342 - val_loss: 1.4575 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1259 - accuracy: 0.5402\n",
      "Epoch 62: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1259 - accuracy: 0.5402 - val_loss: 1.4591 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1247 - accuracy: 0.5252\n",
      "Epoch 63: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1250 - accuracy: 0.5246 - val_loss: 1.4597 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1251 - accuracy: 0.5373\n",
      "Epoch 64: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1248 - accuracy: 0.5366 - val_loss: 1.4598 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1282 - accuracy: 0.5246\n",
      "Epoch 65: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1282 - accuracy: 0.5246 - val_loss: 1.4592 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1240 - accuracy: 0.5312\n",
      "Epoch 66: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1242 - accuracy: 0.5306 - val_loss: 1.4592 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1329 - accuracy: 0.5204\n",
      "Epoch 67: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1328 - accuracy: 0.5210 - val_loss: 1.4595 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1261 - accuracy: 0.5404\n",
      "Epoch 68: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1258 - accuracy: 0.5426 - val_loss: 1.4590 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 69/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1351 - accuracy: 0.5228\n",
      "Epoch 69: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1351 - accuracy: 0.5222 - val_loss: 1.4594 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1330 - accuracy: 0.5368\n",
      "Epoch 70: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1359 - accuracy: 0.5354 - val_loss: 1.4592 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1264 - accuracy: 0.5300\n",
      "Epoch 71: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1264 - accuracy: 0.5294 - val_loss: 1.4584 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1304 - accuracy: 0.5276\n",
      "Epoch 72: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1305 - accuracy: 0.5282 - val_loss: 1.4585 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1296 - accuracy: 0.5168\n",
      "Epoch 73: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1300 - accuracy: 0.5162 - val_loss: 1.4595 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1199 - accuracy: 0.5493\n",
      "Epoch 74: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1191 - accuracy: 0.5498 - val_loss: 1.4603 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1214 - accuracy: 0.5404\n",
      "Epoch 75: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1221 - accuracy: 0.5402 - val_loss: 1.4597 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1246 - accuracy: 0.5433\n",
      "Epoch 76: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1244 - accuracy: 0.5438 - val_loss: 1.4604 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1234 - accuracy: 0.5240\n",
      "Epoch 77: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1237 - accuracy: 0.5234 - val_loss: 1.4594 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1365 - accuracy: 0.5086\n",
      "Epoch 78: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1354 - accuracy: 0.5090 - val_loss: 1.4587 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1297 - accuracy: 0.5110\n",
      "Epoch 79: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1317 - accuracy: 0.5114 - val_loss: 1.4593 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1376 - accuracy: 0.5312\n",
      "Epoch 80: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1377 - accuracy: 0.5318 - val_loss: 1.4597 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1335 - accuracy: 0.5264\n",
      "Epoch 81: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1332 - accuracy: 0.5270 - val_loss: 1.4598 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1228 - accuracy: 0.5257\n",
      "Epoch 82: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1213 - accuracy: 0.5282 - val_loss: 1.4607 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1219 - accuracy: 0.5245\n",
      "Epoch 83: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1223 - accuracy: 0.5246 - val_loss: 1.4608 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1328 - accuracy: 0.5245\n",
      "Epoch 84: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1325 - accuracy: 0.5234 - val_loss: 1.4588 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1242 - accuracy: 0.5319\n",
      "Epoch 85: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1241 - accuracy: 0.5282 - val_loss: 1.4576 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1244 - accuracy: 0.5132\n",
      "Epoch 86: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1244 - accuracy: 0.5126 - val_loss: 1.4602 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1195 - accuracy: 0.5354\n",
      "Epoch 87: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1195 - accuracy: 0.5354 - val_loss: 1.4613 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1145 - accuracy: 0.5270\n",
      "Epoch 88: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1145 - accuracy: 0.5246 - val_loss: 1.4614 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1295 - accuracy: 0.5240\n",
      "Epoch 89: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1294 - accuracy: 0.5234 - val_loss: 1.4611 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1202 - accuracy: 0.5441\n",
      "Epoch 90: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1216 - accuracy: 0.5438 - val_loss: 1.4619 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1289 - accuracy: 0.5196\n",
      "Epoch 91: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1277 - accuracy: 0.5222 - val_loss: 1.4612 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.1211 - accuracy: 0.5208\n",
      "Epoch 92: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1204 - accuracy: 0.5210 - val_loss: 1.4619 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1243 - accuracy: 0.5312\n",
      "Epoch 93: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1248 - accuracy: 0.5306 - val_loss: 1.4610 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1139 - accuracy: 0.5312\n",
      "Epoch 94: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1146 - accuracy: 0.5306 - val_loss: 1.4625 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1213 - accuracy: 0.5264\n",
      "Epoch 95: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1218 - accuracy: 0.5258 - val_loss: 1.4620 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1273 - accuracy: 0.5156\n",
      "Epoch 96: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1272 - accuracy: 0.5150 - val_loss: 1.4618 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1152 - accuracy: 0.5168\n",
      "Epoch 97: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1151 - accuracy: 0.5162 - val_loss: 1.4628 - val_accuracy: 0.3585 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1209 - accuracy: 0.5288\n",
      "Epoch 98: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1206 - accuracy: 0.5294 - val_loss: 1.4639 - val_accuracy: 0.3529 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "52/53 [============================>.] - ETA: 0s - loss: 1.1230 - accuracy: 0.5349\n",
      "Epoch 99: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1230 - accuracy: 0.5342 - val_loss: 1.4653 - val_accuracy: 0.3501 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1342 - accuracy: 0.5066\n",
      "Epoch 100: val_loss did not improve from 1.40804\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1342 - accuracy: 0.5066 - val_loss: 1.4635 - val_accuracy: 0.3557 - lr: 1.0000e-06\n",
      "10/10 [==============================] - 2s 13ms/step - loss: 1.4414 - accuracy: 0.2625\n",
      "Test accuracy: 26.25%\n"
     ]
    }
   ],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(40, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(40)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(10, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab),kernel_regularizer='l2', activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"/home/app/src/experiments/inceptionv3_GRU/exp_006/model.weights_exp_005.h5\"\n",
    "    filepath_log = '/home/app/src/experiments/inceptionv3_GRU/logs'\n",
    "\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.000001)\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "    tensor_board = keras.callbacks.TensorBoard (filepath_log)\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint, reduce_lr, tensor_board],\n",
    "        batch_size = 16,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard == logdir /home/app/src/experiments/inceptionv3_GRU/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [precision, recall,f1,support]=precision_recall_fscore_support(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: /home/app/src/data/shot-type-dataset/trailer_v3/test/shot_tt5498536_0027.mp4\n",
      "  Motion: 32.05%\n",
      "  Pull: 25.26%\n",
      "  Static: 21.72%\n",
      "  Push: 20.97%\n",
      "Real Label: Pull\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4051ab4080d949cf8ec8042bd37688e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free...')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "    return embed.embed_file(\"animation.gif\")\n",
    "\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "test_frames = sequence_prediction(test_video)\n",
    "real_label = test_df[test_df['video_name'] ==test_video]['tag'].iloc[0]\n",
    "print(f'Real Label: {real_label}')\n",
    "new_ = Video.from_file(test_video,play=True)\n",
    "new_\n",
    "#to_gif(test_frames[:MAX_SEQ_LENGTH])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

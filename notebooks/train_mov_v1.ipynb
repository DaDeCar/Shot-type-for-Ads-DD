{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "#from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import imageio\n",
    "import cv2\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2_trailer_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb05013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reading the JSON data using json.load()\n",
    "# file = '/home/app/src/data/shot-type-dataset/v2_full_trailer.json'\n",
    "# with open(file) as train_file:\n",
    "#     dict_v2= json.load(train_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a DataFrame with the v2_full_trailer.json\"\n",
    "\n",
    "# dataset = []\n",
    "# movie = []\n",
    "# shot= []\n",
    "# scale_label = []\n",
    "# scale_val = []\n",
    "# mov_label = []\n",
    "# mov_val = []\n",
    "\n",
    "# # We pass for all JSON keys an append every trailer labels different lists\n",
    "# for key_movie in dict_v2:\n",
    "#     for key_shot in dict_v2[key_movie]:\n",
    "\n",
    "#         dataset.append('v2')\n",
    "#         movie.append(key_movie)\n",
    "#         shot.append(key_shot)\n",
    "#         scale_label.append('None')\n",
    "#         scale_val.append(int(0))\n",
    "#         mov_label.append(dict_v2[key_movie][key_shot]['movement']['label'])\n",
    "#         mov_val.append(dict_v2[key_movie][key_shot]['movement']['value'])\n",
    "\n",
    "# # We build the dataframe with the lists data\n",
    "# data = list(zip(dataset, movie, shot, scale_label, scale_val, mov_label, mov_val))  \n",
    "# columns = ['dataset','movie', 'shot', 'scale_label', 'scale_val', 'move_label', 'move_val']  \n",
    "        \n",
    "# dataset_df_v2 = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_df = dataset_df_v2\n",
    "# v2_path = '/workspaces/final-project-shot-type/data/shot-type-dataset/trailer_v2/'\n",
    "# v2_df ['video_name'] = v2_path + 'shot_' + data_df['movie'] + '_' + data_df['shot'] + '.mp4'\n",
    "# v2_df = v2_df[['video_name', 'move_label','scale_label']]\n",
    "# v2_df = v2_df.rename(columns ={'scale_label': 'tag'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2_df.to_csv('/home/app/src/data/CSV/dataset_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2_df= pd.read_csv('/home/app/src/data/CSV/dataset_v2.csv')\n",
    "#v2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Trailer_v3_dataset (The complete dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd. read_csv('/home/app/src/data/CSV/dataset_df.csv', dtype={\"shot\": str})\n",
    "\n",
    "data_df.drop(columns=['scale_val'], inplace=True)\n",
    "data_df.drop(columns = ['move_val'], inplace=True)\n",
    "\n",
    "train_path = '/home/app/src/data/shot-type-dataset/trailer_v3/train/'\n",
    "data_df['video_name'] = train_path + 'shot_' + data_df['movie'] + '_' + data_df['shot'] + '.mp4'\n",
    "train_df = data_df[(data_df['dataset']=='train') | (data_df['dataset']=='val') ]\n",
    "train_df = train_df[['video_name', 'move_label','scale_label']]\n",
    "train_df = train_df.rename(columns ={'scale_label': 'tag'})\n",
    "\n",
    "\n",
    "test_path = '/home/app/src/data/shot-type-dataset/trailer_v3/test/'\n",
    "data_df['video_name'] = test_path + 'shot_' + data_df['movie'] + '_' + data_df['shot'] + '.mp4'\n",
    "test_df = data_df[data_df['dataset']=='test']\n",
    "test_df = test_df[['video_name', 'move_label','scale_label']]\n",
    "test_df = test_df.rename(columns ={'scale_label': 'tag'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>move_label</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25461</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25462</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25463</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25466 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video_name move_label  tag\n",
       "0      /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "1      /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "2      /home/app/src/data/shot-type-dataset/trailer_v...     Static  ECS\n",
       "3      /home/app/src/data/shot-type-dataset/trailer_v...     Static   MS\n",
       "4      /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "...                                                  ...        ...  ...\n",
       "25461  /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "25462  /home/app/src/data/shot-type-dataset/trailer_v...     Motion   MS\n",
       "25463  /home/app/src/data/shot-type-dataset/trailer_v...     Static   FS\n",
       "25464  /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "25465  /home/app/src/data/shot-type-dataset/trailer_v...       Push   CS\n",
       "\n",
       "[25466 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>move_label</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25467</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25468</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25469</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33648</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33649</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33650</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33651</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33652</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8187 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video_name move_label  tag\n",
       "25466  /home/app/src/data/shot-type-dataset/trailer_v...     Static   LS\n",
       "25467  /home/app/src/data/shot-type-dataset/trailer_v...     Static   MS\n",
       "25468  /home/app/src/data/shot-type-dataset/trailer_v...     Static   MS\n",
       "25469  /home/app/src/data/shot-type-dataset/trailer_v...     Static   LS\n",
       "25470  /home/app/src/data/shot-type-dataset/trailer_v...     Motion   FS\n",
       "...                                                  ...        ...  ...\n",
       "33648  /home/app/src/data/shot-type-dataset/trailer_v...     Static   FS\n",
       "33649  /home/app/src/data/shot-type-dataset/trailer_v...     Motion   MS\n",
       "33650  /home/app/src/data/shot-type-dataset/trailer_v...     Motion   FS\n",
       "33651  /home/app/src/data/shot-type-dataset/trailer_v...     Static   LS\n",
       "33652  /home/app/src/data/shot-type-dataset/trailer_v...     Static  ECS\n",
       "\n",
       "[8187 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating TRAIN balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bal_static = train_df[train_df.move_label == 'Static'][0:700]\n",
    "train_df_bal_motion = train_df[train_df.move_label == 'Motion'][0:700]\n",
    "\n",
    "len_push_tag = train_df.move_label[train_df.move_label == 'Push'].shape[0]\n",
    "len_pull_tag = train_df.move_label[train_df.move_label == 'Pull'].shape[0]\n",
    "\n",
    "train_df_bal_push = train_df[train_df.move_label == 'Push'][0:len_push_tag]\n",
    "train_df_bal_pull = train_df[train_df.move_label == 'Pull'][0:len_pull_tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bal = pd.concat([train_df_bal_static, train_df_bal_motion, train_df_bal_pull, train_df_bal_push], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>move_label</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25429</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25436</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25447</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25449</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2220 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video_name move_label  tag\n",
       "0      /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "1      /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "2      /home/app/src/data/shot-type-dataset/trailer_v...     Static  ECS\n",
       "3      /home/app/src/data/shot-type-dataset/trailer_v...     Static   MS\n",
       "4      /home/app/src/data/shot-type-dataset/trailer_v...     Static   CS\n",
       "...                                                  ...        ...  ...\n",
       "25429  /home/app/src/data/shot-type-dataset/trailer_v...       Push   FS\n",
       "25436  /home/app/src/data/shot-type-dataset/trailer_v...       Push   LS\n",
       "25447  /home/app/src/data/shot-type-dataset/trailer_v...       Push   MS\n",
       "25449  /home/app/src/data/shot-type-dataset/trailer_v...       Push  ECS\n",
       "25465  /home/app/src/data/shot-type-dataset/trailer_v...       Push   CS\n",
       "\n",
       "[2220 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding v2_trailers to Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_idx_v2 = []\n",
    "\n",
    "# for x in range(train_df_bal.index[-1]+1,train_df_bal.index[-1]+1+len(v2_df.index )):\n",
    "#     new_idx_v2.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2_df.index = new_idx_v2\n",
    "#v2_df = v2_df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = pd.concat([train_df_bal, v2_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_bal.video_name[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating TEST balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_bal_static = test_df[test_df.move_label == 'Static'][0:150]\n",
    "test_df_bal_motion = test_df[test_df.move_label == 'Motion'][0:150]\n",
    "\n",
    "len_push_tag = test_df.move_label[test_df.move_label == 'Push'].shape[0]\n",
    "len_pull_tag = test_df.move_label[test_df.move_label == 'Pull'].shape[0]\n",
    "\n",
    "test_df_bal_push = test_df[test_df.move_label == 'Push'][0:len_push_tag]\n",
    "test_df_bal_pull = test_df[test_df.move_label == 'Pull'][0:len_pull_tag]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_bal = pd.concat([test_df_bal_static, test_df_bal_motion, test_df_bal_pull, test_df_bal_push], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>move_label</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25467</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25468</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25469</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25471</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28840</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28871</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28894</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28979</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29076</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              video_name move_label  tag\n",
       "25466  /home/app/src/data/shot-type-dataset/trailer_v...     Static   LS\n",
       "25467  /home/app/src/data/shot-type-dataset/trailer_v...     Static   MS\n",
       "25468  /home/app/src/data/shot-type-dataset/trailer_v...     Static   MS\n",
       "25469  /home/app/src/data/shot-type-dataset/trailer_v...     Static   LS\n",
       "25471  /home/app/src/data/shot-type-dataset/trailer_v...     Static  ECS\n",
       "...                                                  ...        ...  ...\n",
       "28840  /home/app/src/data/shot-type-dataset/trailer_v...       Push   FS\n",
       "28871  /home/app/src/data/shot-type-dataset/trailer_v...       Push   LS\n",
       "28894  /home/app/src/data/shot-type-dataset/trailer_v...       Push  ECS\n",
       "28979  /home/app/src/data/shot-type-dataset/trailer_v...       Push  ECS\n",
       "29076  /home/app/src/data/shot-type-dataset/trailer_v...       Push  ECS\n",
       "\n",
       "[380 rows x 3 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming move_label as 'TAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bal = train_df_bal.rename(columns ={'tag':'scale_label'})\n",
    "train_df_bal = train_df_bal.rename(columns ={'move_label':'tag'})\n",
    "train_df_bal = train_df_bal.reset_index(drop = True)\n",
    "\n",
    "test_df_bal = test_df_bal.rename(columns ={'tag':'scale_label'})\n",
    "test_df_bal = test_df_bal.rename(columns ={'move_label':'tag'})\n",
    "test_df_bal = test_df_bal.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.to_csv('/workspaces/final-project-shot-type/data/CSV/dataset_train_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.to_csv('/workspaces/final-project-shot-type/data/CSV/dataset_test_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 2220\n",
      "Total videos for testing: 380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>scale_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Pull</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Motion</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Push</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>LS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>ECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>/home/app/src/data/shot-type-dataset/trailer_v...</td>\n",
       "      <td>Static</td>\n",
       "      <td>FS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             video_name     tag scale_label\n",
       "1319  /home/app/src/data/shot-type-dataset/trailer_v...    Pull          MS\n",
       "1705  /home/app/src/data/shot-type-dataset/trailer_v...    Push          LS\n",
       "200   /home/app/src/data/shot-type-dataset/trailer_v...  Static          MS\n",
       "588   /home/app/src/data/shot-type-dataset/trailer_v...  Static          FS\n",
       "920   /home/app/src/data/shot-type-dataset/trailer_v...  Motion          CS\n",
       "1649  /home/app/src/data/shot-type-dataset/trailer_v...    Push          LS\n",
       "396   /home/app/src/data/shot-type-dataset/trailer_v...  Static          LS\n",
       "353   /home/app/src/data/shot-type-dataset/trailer_v...  Static          LS\n",
       "193   /home/app/src/data/shot-type-dataset/trailer_v...  Static         ECS\n",
       "581   /home/app/src/data/shot-type-dataset/trailer_v...  Static          FS"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df= train_df_bal\n",
    "test_df = test_df_bal\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking correct video tagging with original JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag check train OK\n",
      "tag check test OK\n"
     ]
    }
   ],
   "source": [
    "# reading the JSON data using json.load()\n",
    "json_path = '/home/app/src/data/shot-type-dataset/v1_split_trailer.json'\n",
    "\n",
    "with open(json_path) as train_file:\n",
    "    dict_v1= json.load(train_file)\n",
    "\n",
    "\n",
    "def tag_ckecker (df, json_dict, df_name_to_check):\n",
    "    tag_chek_list = []\n",
    "\n",
    "    for i in range(len(df.index)):\n",
    "        movie = df['video_name'][i]\n",
    "        df_tag = df['tag'][df['video_name'] == movie][i]\n",
    "        find_char_st = movie.find('_', 55,60)\n",
    "        find_char_end = movie.find('_', 65,70)\n",
    "        movie_key = movie[find_char_st+1:find_char_end]\n",
    "        trailer_key =  movie[find_char_end+1:find_char_end+5]\n",
    "        try:\n",
    "            dict_tag = json_dict[df_name_to_check][movie_key][trailer_key]['movement']['label']\n",
    "        except KeyError:\n",
    "            dict_tag = json_dict['val'][movie_key][trailer_key]['movement']['label']\n",
    "\n",
    "            if dict_tag == df_tag:\n",
    "                pass\n",
    "            else:\n",
    "                tag_chek_list.append(movie)\n",
    "\n",
    "    if len(tag_chek_list) == 0:\n",
    "        print(f'tag check {df_name_to_check} OK')\n",
    "    else: print (tag_chek_list)\n",
    "\n",
    "\n",
    "tag_ckecker(train_df, dict_v1, 'train')\n",
    "tag_ckecker(test_df, dict_v1, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Push      773\n",
       "Static    600\n",
       "Motion    600\n",
       "Pull      247\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading frames and working on frame's size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_1 (TFOpLamb  (None, 224, 224, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_1 (TFOpLam  (None, 224, 224, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " inception_v3 (Functional)   (None, 2048)              21802784  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()\n",
    "print(feature_extractor.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Motion', 'Pull', 'Push', 'Static']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"video_name\"].values.tolist()\n",
    "    labels = df[\"tag\"].values\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
    "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_embeddings= '/home/app/src/embeddings/mov_bal_2k_embeddings_20F/'\n",
    "\n",
    "# Train\n",
    "train_data_embedding_0 = np.save(path_save_embeddings + 'train_data_embedding_0.npy', train_data[0])\n",
    "train_data_embedding_1 = np.save(path_save_embeddings + 'train_data_embedding_1.npy', train_data[1])\n",
    "train_labels_embedding = np.save(path_save_embeddings + 'train_labels_embedding.npy', train_labels)\n",
    "\n",
    "#Test\n",
    "test_data_embedding_0 = np.save(path_save_embeddings + 'test_data_embedding_0.npy', test_data[0])\n",
    "test_data_embedding_1 = np.save(path_save_embeddings + 'test_data_embedding_1.npy', test_data[1])\n",
    "test_labels_embedding = np.save(path_save_embeddings + 'test_labels_embedding.npy', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_load_embeddings= '/home/app/src/embeddings/mov_bal_2k_embeddings_20F/'\n",
    "\n",
    "# #Train\n",
    "# train_data_0 = np.load(path_load_embeddings + 'train_data_embedding_0.npy')\n",
    "# train_data_1 = np.load(path_load_embeddings + 'train_data_embedding_1.npy')\n",
    "# train_data=(train_data_0, train_data_1)\n",
    "# train_labels = np.load(path_load_embeddings + 'train_labels_embedding.npy')\n",
    "\n",
    "# #Test\n",
    "# test_data_0 = np.load(path_load_embeddings + 'test_data_embedding_0.npy')\n",
    "# test_data_1 = np.load(path_load_embeddings + 'test_data_embedding_1.npy')\n",
    "# test_data=(test_data_0, test_data_1)\n",
    "# test_labels = np.load(path_load_embeddings + 'test_labels_embedding.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence model (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.2984 - accuracy: 0.3668\n",
      "Epoch 1: val_loss improved from inf to 2.05898, saving model to /home/app/src/experiments/inceptionv3_GRU/exp_006/model.weights_exp_005.h5\n",
      "49/49 [==============================] - 13s 91ms/step - loss: 1.2984 - accuracy: 0.3668 - val_loss: 2.0590 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.2370 - accuracy: 0.3964\n",
      "Epoch 2: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.2370 - accuracy: 0.3964 - val_loss: 2.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.2192 - accuracy: 0.4015\n",
      "Epoch 3: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.2192 - accuracy: 0.4015 - val_loss: 2.3507 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.2098 - accuracy: 0.4028\n",
      "Epoch 4: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 1.2098 - accuracy: 0.4028 - val_loss: 2.2828 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.2081 - accuracy: 0.4176\n",
      "Epoch 5: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 1.2081 - accuracy: 0.4176 - val_loss: 2.3616 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1879 - accuracy: 0.4434\n",
      "Epoch 6: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.1879 - accuracy: 0.4434 - val_loss: 2.2738 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1778 - accuracy: 0.4421\n",
      "Epoch 7: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.1778 - accuracy: 0.4421 - val_loss: 2.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1711 - accuracy: 0.4575\n",
      "Epoch 8: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.1711 - accuracy: 0.4575 - val_loss: 2.3330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1607 - accuracy: 0.4665\n",
      "Epoch 9: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 1.1607 - accuracy: 0.4665 - val_loss: 2.4110 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1459 - accuracy: 0.4788\n",
      "Epoch 10: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.1459 - accuracy: 0.4788 - val_loss: 2.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1363 - accuracy: 0.4878\n",
      "Epoch 11: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 1.1363 - accuracy: 0.4878 - val_loss: 2.3857 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1316 - accuracy: 0.4884\n",
      "Epoch 12: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.1316 - accuracy: 0.4884 - val_loss: 2.3881 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1203 - accuracy: 0.5071\n",
      "Epoch 13: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 1.1203 - accuracy: 0.5071 - val_loss: 2.3913 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.1102 - accuracy: 0.5000\n",
      "Epoch 14: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.1102 - accuracy: 0.5000 - val_loss: 2.4007 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0983 - accuracy: 0.5135\n",
      "Epoch 15: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 1.0983 - accuracy: 0.5135 - val_loss: 2.3044 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0788 - accuracy: 0.5322\n",
      "Epoch 16: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 32ms/step - loss: 1.0788 - accuracy: 0.5322 - val_loss: 2.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.5380\n",
      "Epoch 17: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 33ms/step - loss: 1.0747 - accuracy: 0.5380 - val_loss: 2.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0506 - accuracy: 0.5560\n",
      "Epoch 18: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 1.0506 - accuracy: 0.5560 - val_loss: 2.3997 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0355 - accuracy: 0.5734\n",
      "Epoch 19: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 1.0355 - accuracy: 0.5734 - val_loss: 2.3900 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0130 - accuracy: 0.5927\n",
      "Epoch 20: val_loss did not improve from 2.05898\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 1.0130 - accuracy: 0.5927 - val_loss: 2.4137 - val_accuracy: 0.0000e+00\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3946 - accuracy: 0.3395\n",
      "Test accuracy: 33.95%\n"
     ]
    }
   ],
   "source": [
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"/home/app/src/experiments/inceptionv3_GRU/exp_006/model.weights_exp_005.h5\"\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=0.000001)\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: /home/app/src/data/shot-type-dataset/trailer_v3/test/shot_tt2039393_0013.mp4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sequence_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m test_video \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(test_df[\u001b[39m\"\u001b[39m\u001b[39mvideo_name\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest video path: \u001b[39m\u001b[39m{\u001b[39;00mtest_video\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m test_frames \u001b[39m=\u001b[39m sequence_prediction(test_video)\n\u001b[1;32m     40\u001b[0m \u001b[39m# to_gif(test_frames[:MAX_SEQ_LENGTH])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sequence_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "# def prepare_single_video(frames):\n",
    "#     frames = frames[None, ...]\n",
    "#     frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "#     frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "#     for i, batch in enumerate(frames):\n",
    "#         video_length = batch.shape[0]\n",
    "#         length = min(MAX_SEQ_LENGTH, video_length)\n",
    "#         for j in range(length):\n",
    "#             frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "#         frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "#     return frame_features, frame_mask\n",
    "\n",
    "\n",
    "# def sequence_prediction(path):\n",
    "#     class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "#     frames = load_video(os.path.join(\"test\", path))\n",
    "#     frame_features, frame_mask = prepare_single_video(frames)\n",
    "#     probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "#     for i in np.argsort(probabilities)[::-1]:\n",
    "#         print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "#     return frames\n",
    "\n",
    "\n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "# def to_gif(images):\n",
    "#     converted_images = images.astype(np.uint8)\n",
    "#     imageio.mimsave(\"animation.gif\", converted_images, fps=10)\n",
    "#     return embed.embed_file(\"animation.gif\")\n",
    "\n",
    "\n",
    "test_video = np.random.choice(test_df[\"video_name\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "test_frames = sequence_prediction(test_video)\n",
    "# to_gif(test_frames[:MAX_SEQ_LENGTH])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
